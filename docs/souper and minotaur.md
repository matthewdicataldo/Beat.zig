# **A Comprehensive Guide to Superoptimization of Zig Code with Souper and Minotaur**

## **Introduction**

This report serves as the definitive technical guide for leveraging advanced superoptimizers—specifically Google's Souper and the University of Utah's Minotaur—to analyze and enhance code generated by the Zig programming language. The integration of these powerful but distinct technologies presents a unique opportunity for systems programmers and compiler engineers to achieve a level of code optimization that transcends the capabilities of conventional, heuristic-based compilers. By providing a formal, proof-based methodology for discovering optimal instruction sequences, this combination allows developers to unlock new performance potentials and gain profound insights into the behavior of their compiled code.

The principle of superoptimization represents a paradigm shift from traditional compiler optimization strategies. Instead of relying on a predefined set of pattern-matching rules and heuristics, a superoptimizer performs an exhaustive, formally verified search for the most efficient instruction sequence that is semantically equivalent to a given code fragment.1 Souper embodies this principle by focusing on integer scalar operations, using Satisfiability Modulo Theories (SMT) solvers to identify peephole optimizations often missed by LLVM's mid-end optimizers.29 While some of its authors are employed by Google, it is not an official Google product.29 Minotaur complements this by specializing in the optimization of integer and floating-point SIMD (Single Instruction, Multiple Data) vector code, a domain not covered by Souper.30

The challenge and opportunity of this guide lie in bridging the gap between Zig's modern language design and the specialized, research-oriented analysis capabilities of these tools. This is a non-trivial endeavor, complicated by the practical realities of toolchain compatibility and the nuanced, evolving relationship between the Zig compiler and its LLVM backend. This report will navigate these technical complexities to present a clear, end-to-end workflow. It will equip the advanced programmer with the foundational knowledge, practical steps, and strategic insights required to successfully apply a dual-superoptimizer strategy to Zig programs, ultimately enabling a deeper, more comprehensive level of performance engineering and code analysis.

## **Section 1: Foundational Concepts in the Zig and LLVM Ecosystem**

A successful integration of Zig with Souper and Minotaur requires a solid understanding of the core principles and architectures of all technologies, as well as the critical role of the LLVM project as the bridge between them. This section establishes the necessary theoretical groundwork, exploring the "what" and "why" of superoptimization, the internal architecture of the superoptimizers, and the strategic direction of Zig's compilation model.

### **1.1 The Principle of Superoptimization**

Superoptimization is a compiler optimization technique that seeks to find the optimal code sequence for a given computation. Unlike traditional compilers, which apply a series of heuristic-based transformation passes (such as constant folding, dead code elimination, or loop unrolling), a superoptimizer operates by performing an exhaustive search over a space of possible instruction sequences to find the one with the lowest cost—typically the shortest or fastest—that is provably equivalent to the original code.1 This brute-force or synthesis-based approach allows it to discover non-obvious optimizations that are not encoded in a standard compiler's repertoire of patterns.

At the heart of modern superoptimizers like Souper and Minotaur is the use of automated theorem provers, specifically Satisfiability Modulo Theories (SMT) or Boolean Satisfiability (SAT) solvers.30 They formulate the optimization problem as a logical query. A tool takes a segment of code, referred to as the Left-Hand Side (LHS), and asks the SMT solver to synthesize a new, lower-cost sequence, the Right-Hand Side (RHS), that is semantically equivalent for all possible inputs. The solver's ability to produce a proof of unsatisfiability for the negation of this equivalence (i.e., proving that there is no input for which

LHS\!= RHS) provides a formal guarantee of the optimization's correctness.33 This proof-based methodology is a fundamental departure from heuristic methods, offering a higher degree of confidence in the transformation's validity.

These tools are designed with two primary use cases in mind, reflecting their dual role as both research tools and practical optimizers:

1. **Offline Analysis for Compiler Developers:** In this mode, the tools analyze large bodies of code to discover new, generalizable peephole optimizations. The results are presented to compiler engineers as actionable advice, suggesting new patterns that can be manually implemented as permanent optimization passes in the LLVM compiler.30 Several optimizations found by both Souper and Minotaur have been incorporated into mainstream compilers this way.29  
2. **Online, Automated Optimization:** The tools can also be used directly during the compilation of a specific program. They can be invoked as standalone tools on an LLVM bitcode file or, more powerfully, loaded as dynamic library passes within the LLVM optimizer (opt) or Clang frontend. In this mode, they find and apply optimizations directly to the program's IR, potentially enabling further downstream optimizations by other LLVM passes.29

### **1.2 Architectural Deep Dive: Google's Souper**

To effectively use Souper, it is essential to understand its internal architecture and how it represents and processes code. Souper does not operate directly on raw LLVM IR; instead, it translates relevant parts of it into its own specialized intermediate representation, detailed in the InstRef.md documentation.29

Souper's core data structure is a purely functional, directed acyclic dataflow graph (DAG). This internal IR is closely modeled on the integer, scalar subset of the LLVM instruction set, comprising 51 distinct instructions.2 Key characteristics of this IR include:

* **Functional Nature:** It is a side-effect-free representation, where each instruction produces a new value from its inputs.  
* **Integer and Scalar Focus:** It deliberately excludes floating-point operations, vector (SIMD) types, and memory operations like load and store.3  
* **Bitwidth Polymorphism:** Most operations are polymorphic with respect to the bit width of their operands, with the synthesizer handling the specific constraints.2  
* **Intrinsics Support:** It explicitly models several important LLVM intrinsics, such as ctpop (count population/Hamming weight), ctlz (count leading zeros), cttz (count trailing zeros), and bswap (byte swap), which are crucial for many low-level optimizations.2  
* **Undefined Behavior:** Certain instructions, such as addnsw (add with no signed wrap), have undefined behavior in specific cases. This is treated similarly to LLVM's "poison values," where Souper may substitute a poison value with any value of its choosing. However, there is a known unsoundness issue where Souper may incorrectly propagate poison values through untaken predecessors of phi nodes, potentially leading to invalid transformations being deemed valid.29

A significant design choice in Souper's IR is the complete absence of explicit control flow constructs like branches or loops. To reason effectively about programs that contain rich control flow, Souper uses two powerful mechanisms to model the dataflow facts that arise from it:

1. **Path Conditions:** When Souper's extractor traverses a conditional branch in the source LLVM IR, it generates a pc (path condition) instruction. This instruction asserts a dataflow fact that is known to be true within that path. For example, after an if (x \> 5\) branch, Souper can add a path condition asserting that the value corresponding to x is indeed greater than 5, which can unlock further simplifications.29  
2. **Blockpcs:** This construct is essentially a reverse path condition used to reason about dataflow that converges at phi nodes. It allows Souper to preserve and utilize the correlation between values that are selected by a phi node based on which predecessor block was executed, enabling optimizations across merged control flow paths.29

The process of creating an optimization candidate begins with Souper extracting an LHS from the input LLVM IR. It starts at an instruction that returns an integer-typed value and recursively traverses the dataflow graph backwards, following operand dependencies. As it encounters conditional branches and phi nodes, it enriches the LHS with the corresponding path conditions and blockpcs. This traversal is carefully bounded to ensure soundness, stopping when it encounters function boundaries, memory loads, or instructions it does not model.2 The resulting LHS, a rich dataflow graph annotated with semantic facts, is then passed to the synthesis engine.

### **1.3 Complementary Superoptimizers: Souper and Minotaur**

While Souper provides powerful analysis for a specific class of operations, Minotaur offers a complementary set of capabilities, making a combined approach particularly effective. Minotaur is a synthesizing superoptimizer that focuses on a different, and equally important, part of the LLVM IR space: **SIMD vector instructions**.30

Key characteristics of Minotaur include:

* **SIMD and Vector Focus:** Minotaur is specifically designed to optimize LLVM's portable vector operations and x86-64 specific SIMD intrinsics, covering both integer and floating-point vector code.30 This is the primary area where Souper's capabilities are limited.  
* **Hybrid Synthesis Algorithm:** Minotaur employs a hybrid synthesis approach where instructions are enumerated concretely, but literal constants are generated by the SMT solver.32  
* **Verification via Alive2:** Minotaur uses Alive2, a formal verification tool for LLVM, as its verification engine to prove the correctness of synthesized optimizations.32

By using both tools, a developer can cover a much broader spectrum of optimization opportunities within their Zig code. Souper excels at finding clever bit-twiddling and arithmetic optimizations in scalar integer code, which is common in cryptography, parsers, and state machines. Minotaur, in contrast, is designed to find performance gains in data-parallel code that leverages SIMD instructions, such as in multimedia processing, scientific computing, and high-performance libraries.30

### **1.4 Zig's Evolving Relationship with LLVM**

The feasibility of using these superoptimizers with Zig is entirely predicated on Zig's ability to produce LLVM IR, their required input format. Understanding the Zig compiler's relationship with the LLVM project is therefore not just background information; it is central to the entire integration strategy.

Currently, the official Zig compiler relies heavily on LLVM as its primary compilation backend. For performance-oriented build modes like ReleaseFast and ReleaseSafe, Zig's frontend performs semantic analysis and generates Zig's internal IR, which is then lowered to LLVM IR. This LLVM IR is handed off to LLVM's mature optimization pipeline and code generators to produce highly optimized machine code.5 This dependency is what allows Zig to achieve performance competitive with C and to support the vast array of hardware targets that LLVM supports.5 When a user sees the message "LLVM Emit Object" during a build, it is a direct observation of this process in action.7

However, the Zig project is undertaking a strategic, long-term "divorce" from its tight coupling with LLVM, with the goal of making the LLVM backend an optional component rather than a hard dependency.9 This initiative is driven by several key motivations:

* **Compile-Time Performance:** A significant portion of the compilation time, especially for non-optimized debug builds, is spent within LLVM's C++ libraries. By providing its own, simpler backends, Zig can dramatically speed up the edit-compile-test cycle for developers.9  
* **Compiler Size and Simplicity:** The LLVM libraries are massive. A Zig compiler built without LLVM is an order of magnitude smaller (e.g., \~4 MB vs. \~170 MB), making it easier to distribute and use in resource-constrained environments.12  
* **Bootstrapping:** Building LLVM is a complex process requiring a modern C++ compiler and other tools. A Zig compiler without this dependency can be bootstrapped with only a simple C compiler, greatly simplifying the process of porting Zig to new platforms.12

Crucially, this decoupling does not mean Zig will lose the ability to generate LLVM IR. The technical strategy is to change the *interface* between the Zig compiler and the LLVM toolchain. Instead of being tightly integrated by linking against LLVM's C++ libraries and using the IRBuilder C++ API, the Zig compiler is gaining the ability to directly emit LLVM bitcode (.bc) or human-readable IR (.ll) files as a compilation target.10 These files can then be processed by any external, system-installed LLVM toolchain for final optimization and code generation.

This strategic shift is the primary enabler for the workflow described in this guide. By formalizing the emission of LLVM IR files as a core compiler feature, Zig makes the integration with external LLVM-based tools like Souper and Minotaur more explicit, stable, and robust. It transforms what might have been a fragile, internal API-based hack into a clean, file-based, and officially supported interaction. Furthermore, the value of these tools should not be misconstrued as a magic wand for performance. Their internal cost models, often based on simple metrics like instruction count, do not always perfectly align with the complex performance characteristics of modern CPUs. As a result, a suggested optimization can, in some cases, lead to performance regressions when benchmarked on real hardware.3 Therefore, their greatest value for a Zig developer is not as a tool for blind, automated application of optimizations, but as a powerful discovery engine. Their findings provide highly specific, formally verified, and actionable insights that can guide manual code refactoring, expose performance cliffs, and illuminate the limitations of the current Zig/LLVM compiler backend.

## **Section 2: Toolchain Preparation and Compatibility**

The practical success of integrating Zig with Souper and Minotaur hinges on establishing a compatible and correctly configured build environment. This section provides the detailed, step-by-step procedures for building the necessary tools, with a special focus on navigating the most significant technical challenge: ensuring LLVM version compatibility across the entire toolchain.

### **2.1 Building the Souper Superoptimizer**

Souper must be built from source. The process involves first building its dependencies (including a specific version of LLVM/Clang) and then building Souper itself.

Prerequisites:  
Before beginning, ensure the build environment meets the following requirements 29:

* A reasonably modern Linux or macOS operating system.  
* CMake (version 3.15 or newer is recommended).  
* A modern host C/C++ toolchain (GCC 4.9+ or any recent version of Clang). Note that GCC versions 4.8 and earlier are explicitly incompatible due to a bug in handling multiline string literals.29  
* The zstd compression library and its development headers, which can typically be installed via a system package manager (e.g., sudo apt-get install libzstd-dev on Debian/Ubuntu).29

Step 1: Download and Build Dependencies  
The first and most critical step is to run the build\_deps.sh script located in the root of the Souper repository. This script is not merely a convenience; it is a specification that downloads a precise version of the LLVM, Clang, and Z3 solver source code into the third\_party/ directory and builds them.29 This ensures that Souper is built against the exact library versions with which it is known to be compatible.

Bash

\# From the root of the cloned Souper repository  
$./build\_deps.sh Release

The Release argument specifies the build type for the dependencies. This can be any valid LLVM build type (e.g., Debug, RelWithDebInfo), but it must be consistent throughout the entire build process. Release is the recommended default for general use.29

Step 2: Configure and Build Souper  
With the dependencies successfully built, the next step is to configure and build Souper itself using CMake. It is standard practice to use an out-of-source build directory.

Bash

\# Create and navigate to a build directory  
$ mkdir build  
$ cd build

\# Run CMake to configure the project  
$ cmake \-DCMAKE\_BUILD\_TYPE=Release /path/to/souper

\# Run make to build the Souper executables and libraries  
$ make

Ensure that the \-DCMAKE\_BUILD\_TYPE flag passed to CMake matches the build type used for the dependencies in Step 1\.29

Step 3: Verification  
After the build completes, it is highly recommended to run Souper's internal test suite to verify that the toolchain is functioning correctly.

Bash

\# From the build directory  
$ make check

A successful run of the test suite indicates that the build is sound. The primary executables, including souper and the drop-in compiler wrappers sclang and sclang++, will be located in the build directory (e.g., build/souper).29

### **2.2 Building the Minotaur Superoptimizer**

Minotaur also needs to be built from source and has its own set of specific dependencies, including a particular build of LLVM and its verification engine, Alive2.

Prerequisites:  
Minotaur requires the following dependencies to be installed on the system 35:

* cmake and ninja-build  
* gcc-10 and g++-10  
* redis and redis-server  
* libhiredis-dev, libbsd-resource-perl, libredis-perl  
* libgtest-dev and re2c

On Debian/Ubuntu systems, these can be installed with:

Bash

$ sudo apt-get install cmake ninja-build gcc-10 g++-10 redis redis-server libhiredis-dev libbsd-resource-perl libredis-perl re2c libgtest-dev

Step 1: Build LLVM and Alive2 Dependencies  
Minotaur requires a specific build of LLVM and a custom version of Alive2. The build process involves cloning these repositories and building them before building Minotaur itself.35  
Step 2: Build Minotaur  
Once the dependencies are in place, you can clone and build Minotaur using CMake and Ninja.35

Bash

\# Clone the repository  
$ git clone git@github.com:minotaur-toolkit/minotaur $HOME/minotaur

\# Create and navigate to a build directory  
$ mkdir $HOME/minotaur/build && cd $HOME/minotaur/build

\# Configure the project, pointing to the required LLVM and Alive2 builds  
$ cmake.. \-DALIVE2\_SOURCE\_DIR=$HOME/alive2-intrinsics \\  
           \-DALIVE2\_BUILD\_DIR=$HOME/alive2-intrinsics/build \\  
           \-DCMAKE\_PREFIX\_PATH=$HOME/llvm/build \\  
           \-DCMAKE\_EXPORT\_COMPILE\_COMMANDS=1 \\  
           \-DCMAKE\_BUILD\_TYPE=RelWithDebInfo \-G Ninja

\# Run ninja to build the Minotaur executables and libraries  
$ ninja

Step 3: Verification  
After the build completes, run the test suite to ensure everything is working correctly:

Bash

\# From the build directory  
$ ninja check

### **2.3 The LLVM Versioning Conundrum**

The single greatest obstacle to a successful integration is the potential for LLVM version incompatibility. All three tools—Zig, Souper, and Minotaur—are deeply tied to the LLVM ecosystem, but they may not be tied to the *same version* of LLVM by default.

The core of the problem is that the LLVM IR format, particularly the binary bitcode (.bc) representation, does not guarantee forward or backward compatibility across major versions.12 An IR file generated by a tool using LLVM 18 may be unreadable or miscompiled by a tool built against LLVM 19\. Because the superoptimizers' entire workflow depends on consuming LLVM IR generated by the Zig compiler, their respective LLVM versions must be compatible.

**Tool Dependencies:**

* **Zig:** Each release of the Zig compiler is built against and coupled with a specific major version of the LLVM libraries. For example, Zig 0.13.0 uses LLVM 18\.16  
* **Souper:** Souper's LLVM version is determined by the revision hardcoded into its build\_deps.sh script. As of this writing, it uses a fork of LLVM 18.1.6.29  
* **Minotaur:** Minotaur also has a strict dependency on a specific version of LLVM and Alive2, which must be built from source as part of its setup.35

**The Reconciliation Strategy:** The most reliable and robust strategy to guarantee compatibility is to force all tools to use the exact same LLVM toolchain. A naive approach would be to build separate toolchains, but this is inefficient and still carries a risk of subtle misconfiguration. The gold standard workflow is to create a single, shared LLVM build that all projects will use:

1. **Identify and Build the Canonical LLVM:** Choose a canonical version of LLVM that is compatible with all tools. Given the dependencies, a version from the LLVM 18.x series is a strong candidate. Clone and build this specific version of LLVM/Clang/LLD and install it to a dedicated prefix on your system (e.g., /opt/shared-llvm/).  
2. **Build Souper and Minotaur Against the Shared LLVM:** Configure the CMake builds for both Souper and Minotaur to use this pre-existing LLVM installation instead of running their internal dependency scripts.  
3. **Build Zig Against the Shared LLVM:** Build the Zig compiler from source, configuring its CMake build to use the exact same LLVM installation.

This method, while more involved, completely eliminates any possibility of IR version mismatch and represents the most professional and reliable setup for this kind of advanced toolchain integration.

To aid in planning this process, the following table provides a reference for the LLVM versions associated with various Zig and superoptimizer releases.

| Tool/Version | LLVM Version | Source(s) |
| :---- | :---- | :---- |
| Zig 0.13.0 | 18.x | 16 |
| Souper (current) | 18.1.6 | 29 |
| Minotaur (current) | Requires custom build | 35 |
| Zig master (early 2025\) | 20.x | 13 |

This table highlights the "moving target" nature of the dependency and underscores the importance of verifying the specific versions required for the sources being used.

## **Section 3: The Core Workflow: From Zig Source to Superoptimizer Analysis**

With a compatible toolchain established, the core workflow can proceed. This involves compiling Zig source code into the LLVM Intermediate Representation that the superoptimizers can consume, and then running them to analyze this IR and discover potential optimizations. This section details the practical steps for both stages of the process.

### **3.1 Generating LLVM Intermediate Representation from Zig**

The Zig compiler provides multiple mechanisms for emitting LLVM IR, catering to both simple, one-off analyses and integrated, project-level workflows. The two primary output formats are human-readable LLVM assembly (.ll files) and binary LLVM bitcode (.bc files). While .ll files are invaluable for manual inspection and understanding the compiler's output, the binary .bc format is the more compact, efficient, and conventional format for feeding into other LLVM tools like Souper and Minotaur.17

Method 1: Direct Command-Line Invocation  
For quick experiments or analyzing single files, the zig build-exe and zig build-lib commands offer direct flags to control output generation 20:

* \-femit-llvm-ir: This flag instructs the compiler to output a human-readable .ll file alongside any other generated artifacts. This is the best option for debugging and learning.20  
* \-femit-llvm-bc: This flag instructs the compiler to output a binary .bc bitcode file. This is the preferred input format for programmatic consumption by superoptimizers and other LLVM tools.17

For example, to compile a Zig source file my\_func.zig and generate both a .ll file and a .bc file, the following commands could be used:

Bash

\# Generate a human-readable LLVM IR file named my\_func.ll  
$ zig build-exe my\_func.zig \-femit-llvm-ir

\# Generate a binary LLVM bitcode file named my\_func.bc  
$ zig build-exe my\_func.zig \-femit-llvm-bc

Method 2: Integration with the Zig Build System  
For any real-world project, the Zig build system (build.zig) provides a far more powerful and scalable approach. The build system models the compilation process as a directed acyclic graph of steps, allowing for custom commands and complex dependencies.24 This enables the creation of a fully automated superoptimization pipeline.  
Within a build.zig script, the std.Build.Step.Compile object, returned by b.addExecutable() or b.addStaticLibrary(), exposes methods to access the generated IR artifacts:

* getEmittedLlvmIr(): This method returns a std.Build.File source that represents the generated .ll file.  
* getEmittedLlvmBc(): This method returns a std.Build.File source for the generated .bc file.

These file sources can then be used as inputs to a subsequent custom build step that invokes the superoptimizer toolchains. This approach is superior because it automates the entire process, ensures reproducibility, and integrates seamlessly into the project's existing build logic.

Example: A Target Function and its LLVM IR  
Consider the following Zig function, which contains bitwise logic that may be a candidate for a non-obvious optimization:

Code snippet

// optimize\_me.zig  
pub fn complex\_mask(x: u32) bool {  
    const a \= (x & 0xFF00FF00) \>\> 8;  
    const b \= (x & 0x00FF00FF) \<\< 8;  
    const swapped \= a | b;  
    const check1 \= (swapped & 0xDEADBEEF) \== 0;  
    const check2 \= (swapped & 0x12345678)\!= 0;  
    return check1 and check2;  
}

To generate the LLVM IR for this function, one would use the Zig build system or the command line:

Bash

$ zig build-obj optimize\_me.zig \-femit-llvm-ir \-O ReleaseFast

The resulting optimize\_me.ll file would contain the LLVM IR corresponding to the complex\_mask function, showing the sequence of and, lshr, shl, or, and icmp instructions that the Zig compiler generated. This .ll (or its .bc equivalent) is the concrete artifact that will be fed into the superoptimizers for analysis.

### **3.2 Superoptimizer Analysis: Souper and Minotaur**

Once the LLVM IR has been generated from the Zig source, it can be passed to the superoptimizer executables for analysis. They will extract optimization candidates (LHSs), query the SMT solver to synthesize optimized replacements (RHSs), and report their findings.

Running Souper and Interpreting its Findings  
The basic command to run Souper requires specifying the path to the Z3 SMT solver executable and the input bitcode file 29:

Bash

\# Assumes souper and z3 are in the PATH, and we have optimize\_me.bc  
$ souper \-z3-path=$(which z3) optimize\_me.bc

Souper's output for a successful optimization consists of several parts, all represented in Souper's own IR format 29:

1. **Path Conditions (pc):** Any dataflow facts known to be true for this code path.  
2. **The Left-Hand Side (LHS):** The original sequence of instructions extracted from the LLVM IR, identified by a root infer instruction.  
3. **The Right-Hand Side (RHS):** The new, synthesized, lower-cost instruction sequence that Souper has proven to be equivalent to the LHS.

For instance, Souper might analyze the IR from the complex\_mask example and discover that the entire boolean expression always evaluates to a fixed value. The output might look conceptually like this:

; Souper optimization found:  
; (Path conditions, if any, would appear here)  
%0:i32 \= var  
%1:i32 \= and %0, \-16711936:i32             ; Corresponds to (x & 0xFF00FF00)  
%2:i32 \= lshr %1, 8:i32                    ; Corresponds to \>\> 8  
%3:i32 \= and %0, 16711935:i32              ; Corresponds to (x & 0x00FF00FF)  
%4:i32 \= shl %3, 8:i32                     ; Corresponds to \<\< 8  
%5:i32 \= or %2, %4                         ; Corresponds to swapped \= a | b  
;... further instructions for the checks...  
%10:i1 \= and %8, %9                        ; Corresponds to check1 and check2  
infer %10  
\=\>  
cand 0:i1

This output indicates that the entire complex sequence of operations rooted at %10 can be replaced with the constant boolean value false (0:i1). Interpreting this result requires mapping the Souper IR variables (%0, %1, etc.) back to the corresponding LLVM IR instructions and, ultimately, to the logic in the original Zig source code. This provides the developer with a precise, verified insight: the function complex\_mask can be optimized to simply return false;.

Running Minotaur and Interpreting its Findings  
Minotaur can be run in two primary modes: online and offline. The online mode applies optimizations during compilation, while the offline mode is designed for parallel analysis and caching.35

* **Online Mode:** Use the minotaur-cc or minotaur-cxx compiler wrappers, with the pass enabled via an environment variable.35  
  Bash  
  $ export ENABLE\_MINOTAUR=ON  
  $ /path/to/minotaur/build/minotaur-cc my\_vector\_code.c \-o my\_vector\_code.o

* **Offline Mode:** The offline mode is a two-step process. First, extract optimization candidates (cuts) into the Redis cache without performing synthesis. Second, run the cache-infer tool to process the cached cuts in parallel.35  
  Bash  
  \# Step 1: Extract cuts into the cache  
  $ export ENABLE\_MINOTAUR=ON  
  $ export MINOTAUR\_NO\_INFER=ON  
  $ /path/to/minotaur/build/minotaur-cc my\_project\_sources...

  \# Step 2: Run synthesis on the cached cuts  
  $ /path/to/minotaur/build/cache-infer

After the cache is populated, recompiling the project with the online mode will apply the newly discovered optimizations.

## **Section 4: Closing the Loop: Applying Optimizations and Creating an Executable**

Discovering a potential optimization is only the first step. The ultimate goal is to produce a final, optimized executable that incorporates the improvements found by the superoptimizers. This can be achieved through a fully automated path using their respective LLVM passes or a more manual, multi-stage process.

### **4.1 The Automated Path: Using LLVM Passes**

For maximum integration and effectiveness, both Souper and Minotaur provide their functionality as standard LLVM passes, packaged in shared libraries. When run as a pass, their improvements can be immediately seen and exploited by subsequent passes in the LLVM optimization pipeline, such as constant propagation and dead code elimination. This can lead to a cascading effect, unlocking further optimizations that would not be possible if the tools were run in isolation.2 This makes the pass-based approach technically superior for achieving the best final result.

Using with opt:  
The opt tool is LLVM's modular optimizer, designed to run arbitrary sequences of optimization passes on an IR file. It is the most direct way to apply the superoptimizer passes:

* **Souper:**  
  Bash  
  \# Assumes the Souper build directory is in the library path  
  $ /path/to/opt \-load /path/to/libsouperPass.so \-souper \\  
        \-z3-path=/usr/bin/z3 \-o /path/to/file.opt.bc \\  
        /path/to/file.bc

  This command loads the Souper pass library, runs the \-souper pass on the bitcode, and writes the transformed bitcode to a new file.29  
* **Minotaur:**  
  Bash  
  \# Assumes the Minotaur build directory is in the library path  
  $ /path/to/opt \-load-pass-plugin /path/to/minotaur/build/online.so \\  
        \-passes="minotaur" \-o /path/to/file.opt.bc /path/to/file.bc

  This command loads the Minotaur pass plugin and runs the \-passes="minotaur" pass.35

Using with Compiler Wrappers:  
Both tools also provide drop-in compiler replacements that automatically apply the pass during compilation, simplifying integration into existing build systems that use standard CC and CXX environment variables.29

* **Souper:** sclang and sclang++  
  Bash  
  $ /path/to/configure CC=/path/to/sclang CXX=/path/to/sclang++  
  $ make

* **Minotaur:** minotaur-cc and minotaur-cxx  
  Bash  
  $ export ENABLE\_MINOTAUR=ON  
  $ /path/to/configure CC=/path/to/minotaur-cc CXX=/path/to/minotaur-cxx  
  $ make

### **4.2 From Optimized Bitcode to a Native Executable**

Whether the optimized bitcode was generated by opt or another method, the final step is to compile it into a native executable. This is a two-stage process: compiling the IR to a machine-specific object file, and then linking that object file with the necessary system libraries.

Step 1: Code Generation with llc  
The LLVM Static Compiler, llc, is the tool responsible for this first stage. It takes an LLVM IR file (.ll or .bc) as input and produces either an assembly file (.s) or, more usefully, a binary object file (.o) for a specific target architecture.18

Bash

\# Compile the optimized bitcode to an object file  
$ llc \-filetype=obj my\_program.opt.bc \-o my\_program.opt.o

This command reads my\_program.opt.bc and generates my\_program.opt.o, a standard object file containing native machine code.

Step 2: Linking  
The generated object file contains the compiled code for the program but lacks the necessary connections to system libraries (like libc for functions such as printf). The linking stage resolves these external dependencies and creates the final executable.  
While a standard system linker like gcc or clang can be used, the ideal choice for a Zig-centric workflow is Zig's own C compiler frontend, zig cc. zig cc is a wrapper around the Clang/LLVM toolchain that Zig bundles, but it transparently integrates Zig's powerful cross-compilation capabilities and its managed libc distributions.5 Using

zig cc for the final link step ensures that the process is seamless, even when cross-compiling.

Bash

\# Link the object file into a native executable using zig cc  
$ zig cc my\_program.opt.o \-o my\_program

\# To cross-compile, simply add the \-target flag  
$ zig cc my\_program.opt.o \-o my\_program\_arm \-target aarch64-linux-gnu

This ability to leverage Zig's cross-compilation toolchain at the final linking stage is a significant advantage. It allows a developer to perform the entire superoptimization and compilation pipeline for a target like ARM64 on an x86-64 development machine without needing to manually install and configure a separate cross-linking toolchain.

### **4.3 Performance Considerations: Caching**

A major practical challenge when using superoptimizers is their computational expense. The process of SMT solving is inherently slow, and the initial compilation of a large project can be 5 to 25 times slower than a normal compilation.2 To mitigate this, both Souper and Minotaur include a crucial feature: a persistent query cache using Redis.

When a superoptimizer encounters an LHS, it first checks the Redis cache. If the result for that LHS is already present, it uses the cached result instantly, bypassing the expensive SMT solver query entirely.29 This dramatically speeds up subsequent builds of the same or similar code.

**Configuration:**

* **Redis Server:** A Redis server (version 1.2.0 or newer for Souper) must be installed and running on the default port (6379) on the machine where the tools are being executed.29  
* **Souper Flag:** The cache is enabled by passing the \-souper-external-cache flag to the Souper pass or by using the sclang and sclang++ wrappers, which enable it by default.29  
* **Minotaur:** Caching is integral to its offline workflow.35

Important Caveat: Cache Invalidation  
The Redis cache used by these tools currently has no built-in support for versioning. If the superoptimizer or its underlying LLVM toolchain is upgraded, the cached results may become invalid or incompatible. It is the user's responsibility to manually clear the Redis cache (e.g., via redis-cli FLUSHALL or by deleting the Redis dump file) whenever the toolchain is modified to prevent stale or incorrect optimizations from being applied.29

## **Section 5: Advanced Topics and Future Outlook**

While the core workflow provides a powerful capability, a comprehensive understanding requires acknowledging the practical limitations of the current tools and considering the future trajectory of the technologies involved. This section addresses known constraints, strategic workarounds, and the long-term relevance of this integration.

### **5.1 Known Limitations and Complementary Strengths**

Developers employing this dual-superoptimizer pipeline must be aware of the distinct strengths and limitations of each tool and how they interact with Zig's language features.

Complementary IR Coverage:  
The most significant distinction lies in their IR coverage. By using both tools, developers can analyze a much wider range of code:

* **Souper:** Its analysis is restricted to the **integer scalar** subset of LLVM IR. It has no understanding of floating-point arithmetic, vector (SIMD) operations, or direct memory access instructions.3 This makes it most effective on integer-heavy, computational code, such as that found in cryptography, data serialization, or state machine logic.  
* **Minotaur:** Its focus is on **integer and floating-point SIMD vector** instructions.30 This directly covers the primary gap in Souper's analysis, making it ideal for data-parallel code found in multimedia applications, scientific computing, and other high-performance domains.

Cost Model vs. Reality:  
Both tools are guided by a cost model to determine whether a synthesized RHS is "cheaper" than the original LHS. This cost model is relatively simple, often based on instruction counts.14 However, this abstract cost does not always correlate directly with execution speed on a physical CPU. Factors like instruction latency, throughput, and micro-architectural hazards are not fully captured. Consequently, an optimization that reduces the instruction count may not necessarily improve performance and, in some cases, can even lead to a slowdown.3 The only way to be certain of a performance improvement is to rigorously benchmark the final executable generated with and without the applied optimizations.  
The @cImport Black Box:  
Zig's world-class C interoperability is primarily enabled by the @cImport builtin, which uses an integrated instance of Clang to parse C header files and generate corresponding Zig type definitions and function stubs.26 When a Zig program calls an imported C function, the LLVM IR for that C function is generated by this internal Clang instance, not by the main Zig-to-LLVM pipeline. This creates a seam in the IR that is difficult for a single superoptimizer run to analyze across. To effectively superoptimize a mixed Zig/C project, a more robust strategy is required:

1. Compile the C parts of the project to LLVM bitcode separately using clang \-c \-emit-llvm.  
2. Compile the Zig parts of the project to LLVM bitcode using zig build-lib.  
3. Use llvm-link to merge the C and Zig bitcode files into a single module.  
4. Run Souper and/or Minotaur on the final, merged bitcode file.  
   This multi-step process ensures that the tools have a complete view of the dataflow, even when it crosses the language boundary.

Known Unsoundness:  
As documented in its InstRef.md file, Souper has a known unsoundness issue related to its handling of undefined behavior. Per LLVM's rules, "poison" values resulting from undefined behavior should not propagate through untaken predecessors of phi nodes. Souper's current implementation does propagate them, which can result in it proposing invalid transformations.29

### **5.2 The Future of Zig, LLVM, and Advanced Optimization**

The technological landscape of compilers is constantly evolving, and the long-term relevance of this workflow depends on the strategic direction of the Zig project.

Relevance in a Post-LLVM Zig:  
As discussed previously, Zig is actively developing its own self-hosted compiler backends to reduce its dependency on LLVM.6 As these backends mature, particularly for debug builds, the LLVM backend will transition from a necessity to an option, likely reserved for achieving the highest levels of optimization in release builds. However, the core strategy of this transition involves formalizing the ability to emit LLVM IR files.10 This ensures that the fundamental workflow described in this guide—compiling Zig to a  
.bc file for consumption by an external tool—will remain a viable and supported, if specialized, pathway. The ability to leverage the vast LLVM ecosystem for deep analysis will be preserved, even as the default compilation path changes.

A Template for Broader Tool Integration:  
The techniques and pipeline architecture detailed in this report are not exclusively applicable to Souper and Minotaur. The core challenge addressed is the generic one of bridging the Zig compiler with the broader LLVM ecosystem via a file-based IR interface. The four-step process—(1) emit .bc from Zig, (2) ensure LLVM version compatibility, (3) run an external tool on the .bc file, and (4) link the result with zig cc—forms a reusable template. A developer could substitute the superoptimizers with any other tool that consumes LLVM IR, such as advanced static analyzers, formal verification tools (like Alive2), or custom instrumentation and fuzzing frameworks. This guide therefore serves as a blueprint for a wide range of advanced compiler toolchain integrations with Zig. The absence of a C API for these tools, which might initially seem like a limitation, is actually a benefit in this context. A command-line, file-based interface is far more decoupled and robust than a language-level binding to a version-sensitive C++ API like LLVM's. This aligns perfectly with Zig's philosophy of explicit, loosely coupled components.  
Potential for a Zig-Native Superoptimizer:  
Looking further into the future, the development of Zig's own well-defined Intermediate Representations, ZIR (Zig IR) and AIR (Analyzed IR), opens up new possibilities.21 As the Zig compiler infrastructure matures and the community grows, it is conceivable that analysis tools could be developed to operate directly on these native IRs. A future Zig-native superoptimizer could leverage the language's rich compile-time features and explicit memory management to perform analyses that are even more powerful than what is possible on the more generic LLVM IR. While this remains a long-term prospect, it represents a natural evolution of the principles of deep, language-aware optimization within the Zig ecosystem.

## **Conclusion**

The integration of the Zig programming language with advanced superoptimizers like Souper and Minotaur represents a powerful, albeit technically demanding, frontier in performance engineering. This report has detailed a comprehensive, end-to-end workflow that enables developers to apply proof-based optimization techniques to their Zig programs, covering both scalar and vector computations. By navigating the complexities of toolchain compatibility and leveraging the evolving architecture of the Zig compiler, it is possible to create a robust and automated analysis pipeline.

The complete workflow can be summarized as follows: First, establish a compatible build environment by constructing a shared LLVM toolchain that satisfies the precise version requirements of Zig, Souper, and Minotaur. Second, use the Zig compiler, preferably through its integrated build system, to compile the target Zig code into LLVM bitcode (.bc files). Third, process this bitcode using the superoptimizer toolchains—Souper for scalar integer logic and Minotaur for SIMD vector code—ideally via their LLVM passes loaded into opt. Fourth, compile the resulting optimized bitcode into a native object file using the LLVM static compiler, llc. Finally, link this object file into a final executable using zig cc, which preserves Zig's powerful cross-compilation capabilities.

This process provides an unparalleled method for discovering non-obvious, formally verified peephole optimizations that lie beyond the reach of standard heuristic-based compilers. While the tools' abstract cost models necessitate careful, benchmark-driven application of their findings, the insights they provide are invaluable. They empower developers to reason about their code's performance at the machine level with a degree of precision and confidence that is rarely achievable.

Ultimately, this integration embodies the core philosophies of Zig and the superoptimizer community: providing maximum control, transparency, and analytical power to the expert programmer. The techniques outlined here serve not only as a specific guide for Souper and Minotaur but also as a general template for interfacing Zig with the vast ecosystem of LLVM-based analysis tools. It is a potent combination for those who seek to push the boundaries of software performance and maintain robust, optimal, and reusable code. The Souper project itself is open-source under the Apache 2.0 license.29

#### **Works cited**

1. Souper – A Superoptimizer for LLVM IR | Hacker News, accessed June 15, 2025, [https://news.ycombinator.com/item?id=10463312](https://news.ycombinator.com/item?id=10463312)  
2. A Synthesizing Superoptimizer \- arXiv, accessed June 15, 2025, [https://arxiv.org/pdf/1711.04422](https://arxiv.org/pdf/1711.04422)  
3. Souper-Charging Peepholes with Target Machine Info \- LLVM.org, accessed June 15, 2025, [https://llvm.org/devmtg/2019-10/slides/Hsu-Souper-ChargingPeepholes.pdf](https://llvm.org/devmtg/2019-10/slides/Hsu-Souper-ChargingPeepholes.pdf)  
4. Souper Results 2 \- Embedded in Academia, accessed June 15, 2025, [https://blog.regehr.org/archives/1192](https://blog.regehr.org/archives/1192)  
5. Overview \- Zig Programming Language, accessed June 15, 2025, [https://ziglang.org/learn/overview/](https://ziglang.org/learn/overview/)  
6. Cross-compilation roadmap and LLVM-- \- Brainstorming \- Ziggit, accessed June 15, 2025, [https://ziggit.dev/t/cross-compilation-roadmap-and-llvm/4098](https://ziggit.dev/t/cross-compilation-roadmap-and-llvm/4098)  
7. LLVM Emit Object? : r/Zig \- Reddit, accessed June 15, 2025, [https://www.reddit.com/r/Zig/comments/1hznwb2/llvm\_emit\_object/](https://www.reddit.com/r/Zig/comments/1hznwb2/llvm_emit_object/)  
8. cImport going away \- Explain \- Ziggit, accessed June 15, 2025, [https://ziggit.dev/t/cimport-going-away/5132](https://ziggit.dev/t/cimport-going-away/5132)  
9. Is it true that Zig wants to move away from LLVM? \- Reddit, accessed June 15, 2025, [https://www.reddit.com/r/Zig/comments/18x1wce/is\_it\_true\_that\_zig\_wants\_to\_move\_away\_from\_llvm/](https://www.reddit.com/r/Zig/comments/18x1wce/is_it_true_that_zig_wants_to_move_away_from_llvm/)  
10. What's replacing LLVM? I didn't think LLVM was a problem, rather a necessary dep... | Hacker News, accessed June 15, 2025, [https://news.ycombinator.com/item?id=39154513](https://news.ycombinator.com/item?id=39154513)  
11. They want to replace LLVM with their own backends. Zig's master branch can now b... | Hacker News, accessed June 15, 2025, [https://news.ycombinator.com/item?id=39154574](https://news.ycombinator.com/item?id=39154574)  
12. directly output LLVM bitcode rather than using LLVM's IRBuilder API · Issue \#13265 · ziglang/zig \- GitHub, accessed June 15, 2025, [https://github.com/ziglang/zig/issues/13265](https://github.com/ziglang/zig/issues/13265)  
13. ziglang/zig: General-purpose programming language and ... \- GitHub, accessed June 15, 2025, [https://github.com/ziglang/zig](https://github.com/ziglang/zig)  
14. A Superoptimizer for LLVM IR \- Hacker News, accessed June 15, 2025, [https://news.ycombinator.com/item?id=26020879](https://news.ycombinator.com/item?id=26020879)  
15. Bump minimum LLVM version to LLVM 6 · Issue \#55842 · rust-lang/rust \- GitHub, accessed June 15, 2025, [https://github.com/rust-lang/rust/issues/55842](https://github.com/rust-lang/rust/issues/55842)  
16. Is Zig using an outdated LLVM? \- Reddit, accessed June 15, 2025, [https://www.reddit.com/r/Zig/comments/1j1pq4z/is\_zig\_using\_an\_outdated\_llvm/](https://www.reddit.com/r/Zig/comments/1j1pq4z/is_zig_using_an_outdated_llvm/)  
17. google/souper: A superoptimizer for LLVM IR \- GitHub, accessed June 15, 2025, [https://github.com/google/souper](https://github.com/google/souper)  
18. Compiling LLVM IR to Binary \- Fernando Borretti, accessed June 15, 2025, [https://borretti.me/article/compiling-llvm-ir-binary](https://borretti.me/article/compiling-llvm-ir-binary)  
19. llc \- LLVM static compiler — LLVM 21.0.0git documentation \- LLVM.org, accessed June 15, 2025, [https://llvm.org/docs/CommandGuide/llc.html](https://llvm.org/docs/CommandGuide/llc.html)  
20. zig build-lib  
21. How do i generate IR when building an executable \- Help \- Ziggit, accessed June 15, 2025, [https://ziggit.dev/t/how-do-i-generate-ir-when-building-an-executable/3624](https://ziggit.dev/t/how-do-i-generate-ir-when-building-an-executable/3624)  
22. How to make clang compile to llvm IR \- Stack Overflow, accessed June 15, 2025, [https://stackoverflow.com/questions/9148890/how-to-make-clang-compile-to-llvm-ir](https://stackoverflow.com/questions/9148890/how-to-make-clang-compile-to-llvm-ir)  
23. souper/README.md at main \- GitHub, accessed June 15, 2025, [https://github.com/google/souper/blob/main/README.md](https://github.com/google/souper/blob/main/README.md)  
24. Zig Build System \- Zig programming language, accessed June 15, 2025, [https://ziglang.org/learn/build-system/](https://ziglang.org/learn/build-system/)  
25. Build the LLVM-IR Code to Binary/Executable File \- Rust Users Forum, accessed June 15, 2025, [https://users.rust-lang.org/t/build-the-llvm-ir-code-to-binary-executable-file/99365](https://users.rust-lang.org/t/build-the-llvm-ir-code-to-binary-executable-file/99365)  
26. I've been confused by the statement that "Zig can compile C Code" for quite some... | Hacker News, accessed June 15, 2025, [https://news.ycombinator.com/item?id=35567671](https://news.ycombinator.com/item?id=35567671)  
27. Chapter 4 \- Working with C \- zighelp.org, accessed June 15, 2025, [https://zighelp.org/chapter-4/](https://zighelp.org/chapter-4/)  
28. After a day of programming in Zig \- Michi's Blog, accessed June 15, 2025, [https://blog.lohr.dev/after-a-day-of-programming-in-zig](https://blog.lohr.dev/after-a-day-of-programming-in-zig)  
29. google-souper.txt  
30. Minotaur: A SIMD-Oriented Synthesizing Superoptimizer \- cs.utah.edu, accessed June 15, 2025, [https://users.cs.utah.edu/\~regehr/minotaur-oopsla24.pdf](https://users.cs.utah.edu/~regehr/minotaur-oopsla24.pdf)  
31. Minotaur: A SIMD-Oriented Synthesizing Superoptimizer \- ResearchGate, accessed June 15, 2025, [https://www.researchgate.net/publication/384745693\_Minotaur\_A\_SIMD-Oriented\_Synthesizing\_Superoptimizer](https://www.researchgate.net/publication/384745693_Minotaur_A_SIMD-Oriented_Synthesizing_Superoptimizer)  
32. Automatic generation of peephole superoptimizers | Request PDF \- ResearchGate, accessed June 15, 2025, [https://www.researchgate.net/publication/220938997\_Automatic\_generation\_of\_peephole\_superoptimizers](https://www.researchgate.net/publication/220938997_Automatic_generation_of_peephole_superoptimizers)  
33. Zig by Example, accessed June 15, 2025, [https://zig-by-example.com/](https://zig-by-example.com/)  
34. (PDF) Minotaur: A SIMD-Oriented Synthesizing Superoptimizer \- ResearchGate, accessed June 15, 2025, [https://www.researchgate.net/publication/371223151\_Minotaur\_A\_SIMD-Oriented\_Synthesizing\_Superoptimizer](https://www.researchgate.net/publication/371223151_Minotaur_A_SIMD-Oriented_Synthesizing_Superoptimizer)  
35. minotaur-toolkit/minotaur: A description of Minotaur can be ... \- GitHub, accessed June 15, 2025, [https://github.com/minotaur-toolkit/minotaur](https://github.com/minotaur-toolkit/minotaur)